

% =======================================================================================
\chapter{Funzioni $f:\mathbb{R} \rightarrow \mathbb{R}$ e limiti}

% ---------------------------------------------------------------------------------------
\section{Cenni di topologia per l'analisi}
\begin{definition}[Intervallo] Un intervallo è un sottoinsieme di $\mathbb{R}$, l'insieme dei numeri reali.
\end{definition}
\begin{definition}[Estremi superiore e inferiore] Se esiste, l'\textbf{estremo superiore} $M \in \mathbb{R}$ di un intervallo $E$ è il più piccolo maggiorante (cioè un numero uguale o maggiore di tutti i numeri dell'intervallo $E$), cioè:
    \begin{itemize}
        \item $M \ge x$ ,$\forall x \in E$
        \item $\nexists z$ maggiorante di $E$, con $z < M$
    \end{itemize}
    Se esiste, l'\textbf{estremo inferiore} $m \in \mathbb{R}$ di un intervallo $E$ è il più grande minorante (cioè un numero uguale o minore di tutti i numeri dell'intervallo $E$), cioè:
    \begin{itemize}
        \item $m \le x$ ,$\forall x \in E$
        \item $\nexists z$ minorante di $E$, con $z > m$
    \end{itemize}
\end{definition}
\begin{definition}[Intervallo aperto] Un intervallo aperto è un intervallo che non include nessuno dei suoi estremi.
\end{definition}
\begin{definition}[Intervallo chiuso] Un intervallo chiuso è un intervallo che include tutti i suoi estremi.
\end{definition}
Punti: accumulazione/isolato, interni/esterni/frontiera
Intervalli: limitati/illimitati, aperti/chiusi, intorno
\begin{definition}[Intorno di un punto] L'intorno completo $B(x_0, \varepsilon)$ del punto $x_0$ di raggio $\varepsilon$ è l'intervallo aperto
    \begin{equation}
        B(x_0, \varepsilon) = (x_0 - \varepsilon, x_0 + \varepsilon)  
    \end{equation}
\end{definition}
\begin{definition}[Intorno destro e sinisto] L'intorno destro di un punto $x_0$ della retta reale è l'insieme aperto
    \begin{equation}
        B^+(x_0,\varepsilon) = (x_0, x_0+\varepsilon) \ .
    \end{equation}
L'intorno destro di un punto $x_0$ della retta reale è l'insieme aperto
    \begin{equation}
        B^-(x_0,\varepsilon) = (x_0-\varepsilon, x_0) \ .
    \end{equation}
\end{definition}
\begin{definition}[Intorno di infinito]
L'intorno di $-\infty$ viene definito come l'insieme aperto
    \begin{equation}
        B(-\infty,M) = (-\infty,M)
    \end{equation}
L'intorno di $+\infty$ viene definito come l'insieme aperto
    \begin{equation}
        B(+\infty,M) = (M,+\infty)
    \end{equation}
\end{definition}

\begin{definition}[Punto di accumulazione] 
\end{definition}
\begin{definition}[Punto interno]
\end{definition}

\begin{definition}[{\color{red} Intervallo chiuso}] {\color{red} Un intervallo è chiuso se contiene tutti i suoi punti di accumulazione.}
\end{definition}
\begin{definition}[{\color{red} Intervallo aperto}] {\color{red} Un intervallo è aperto se ogni suo punto è un punto interno.}
\end{definition}

\begin{definition}[]
\end{definition}

% ---------------------------------------------------------------------------------------
\section{Funzioni}
\begin{definition}[Funzione a variabile e valori reali]
\end{definition}

% ---------------------------------------------------------------------------------------
\section{Limiti}
{\color{red}
\begin{itemize}
    \item Limite destro e limite sinistro
    \item Funzioni continue
\end{itemize}
}
\begin{definition}[Limite finito al finito] Il limite finito della funzione $f(x)$  per $x$ che tende a $x_0$,
    \begin{equation}
      \lim_{x \rightarrow x_0} f(x) = \ell
    \end{equation}
    è definito dalla condizione
    \begin{equation}
        \text{Per $\forall \varepsilon > 0$ tale che $|x-x_0| < \varepsilon$, $\exists \delta > 0$ tale che $|f(x) - \ell|< \delta$.}
    \end{equation}
\end{definition}
\begin{definition}[Limite infinito al finito] Il limite infinito della funzione $f(x)$  per $x$ che tende a $x_0$,
    \begin{equation}
      \lim_{x \rightarrow x_0} f(x) = \mp \infty
    \end{equation}
    è definito dalla condizione
    \begin{equation}
        \text{Per $\forall \varepsilon > 0$ tale che $|x-x_0| < \varepsilon$, $\exists M \lessgtr 0$ tale che $f(x) \lessgtr M$.}
    \end{equation}
\end{definition}
\begin{definition}[Limite finito al infinito] Il limite finito della funzione $f(x)$ per $x$ che tende all'infinito
    \begin{equation}
      \lim_{x \rightarrow \mp \infty} f(x) = \ell
    \end{equation}
    è definito dalla condizione
    \begin{equation}
        \text{Per $\forall N \lessgtr 0$ tale che $x \lessgtr  N$, $\exists \delta > 0$ tale che $|f(x) - \ell| < \delta$.}
    \end{equation}
\end{definition}
\begin{definition}[Limite infinito al infinito] Il limite infinito della funzione $f(x)$ per $x$ che tende all'infinito
    \begin{equation}
        \lim_{x \rightarrow \mp^{(1)} \infty} f(x) = \mp^{(2)} \infty
    \end{equation}
    è definito dalla condizione
    \begin{equation}
        \text{Per $\forall N \lessgtr^{(1)} 0$ tale che $x \lessgtr^{(1)} N$, $\exists M \lessgtr^{(2)} 0$ tale che $f(x) \lessgtr^{(2)} M$.}
    \end{equation}
\end{definition}

{\color{red}Grafici}

% ---------------------------------------------------------------------------------------
\section{Funzioni continue}
\begin{definition}[Funzione continua in un punto] Una funzione $f: \Omega \rightarrow \mathbb{R}$ è continua in un punto $x_0 \in \Omega$ se 
    \begin{equation}
        \lim_{x \rightarrow x_0}f(x) = f(x_0) \ .
    \end{equation}
\end{definition}
\begin{definition}[Funzione continua in un intervallo] Una funzione $f: \Omega \rightarrow \mathbb{R}$ è continua in un intervallo $[a, b] \subset \Omega$, se è una funzione continua in tutti i punti $x \in [a, b]$.
\end{definition}

\subsection{Teoremi sulle funzioni continue}
\begin{theorem}[Teorema di Weierstrass]\label{thm:weierstrass} Una funzione continua definita su un intervallo chiuso e limitato $[a, b]$ ammette in esso un massimo e un minimo assoluto.
\end{theorem}

% ---------------------------------------------------------------------------------------
\section{Teoremi sui limiti}
\begin{theorem}[Teorema del confronto]\label{thm:comparison}
\end{theorem}

\begin{theorem}[Teorema di de l'Hopital -- anticipazione]\label{thm:hopital:0} Il teorema di de l'Hopital riguarda il calcolo delle forme indeterminate $\frac{0}{0}$, $\frac{\infty}{\infty}$, cioè i limiti che possono essere scritti nella forma
    \begin{equation}
        \lim_{x \rightarrow x_0} \dfrac{f(x)}{g(x)}
    \end{equation}
    con
    \begin{itemize}
        \item $\lim_{x \rightarrow x_0} f(x) = \lim_{x \rightarrow x_0} g(x) = 0$ oppure
        \item $\lim_{x \rightarrow x_0} |f(x)| = \lim_{x \rightarrow x_0} |g(x)| = +\infty$
    \end{itemize}
\end{theorem}
    Per l'enunciato completo e la dimostrazione del teorema di de l'Hopital si rimanda al teorema \S\ref{thm:hopital} cap.\S\ref{ch:derivatives} sulle derivate.

% ---------------------------------------------------------------------------------------
\section{Infiniti e infinitesimi}

% ---------------------------------------------------------------------------------------
\section{Limiti notevoli}
\begin{center}
\begin{tabular}{ll}
    Potenza            & $\displaystyle\lim_{x \rightarrow 0} \dfrac{(1+x)^a - 1}{x} = a$ \\
    Seno               & $\displaystyle\lim_{x \rightarrow 0} \dfrac{\sin}{x} = 1$ \\
    Coseno             & $\displaystyle\lim_{x \rightarrow 0} \dfrac{1 - \cos x}{x^2} = \frac{1}{2}$ \\
    Esponenziale - def & $\displaystyle\lim_{x \rightarrow \infty} \left( 1 + \dfrac{1}{x} \right)^x = e$ \\
    \qquad " \qquad (1)& $\displaystyle\lim_{x \rightarrow 0} \dfrac{e^x - 1}{x} = 1$ \\
    \qquad " \qquad (2)& $\displaystyle\lim_{x \rightarrow 0} \dfrac{e^{x}}{1+x} = 1$ \\
    Logaritmo naturale & $\displaystyle\lim_{x \rightarrow 0} \dfrac{\ln (1+x)}{x} = 1$ \\
\end{tabular}
\end{center}

\subsection{Dimostrazioni}
\begin{proof}[Limite notevole del seno] Il limite viene calcolato usando il teorema del confronto (\ref{thm:comparison}), con le funzioni $x$, $\sin x$ e $\tan x$
    \begin{equation}
        \sin x \le x \le \tan x \qquad \rightarrow \qquad 1 \le \dfrac{x}{\sin{x}} \le \dfrac{1}{\cos x} \ .
    \end{equation}
    Per $x \rightarrow 0$, $\displaystyle\lim_{x \rightarrow 0} 1 = 1$ e $\displaystyle\lim_{x \rightarrow 0} \frac{1}{\cos x} = 1$ e quindi $ \lim_{x \rightarrow 0} \dfrac{ x }{\sin x} = 1 $.
\end{proof}
\begin{proof}[Limite notevole del coseno] Il limite viene calcolato usando il limite notevole del seno,
    \begin{equation}
        \begin{aligned}
            \lim_{x \rightarrow 0} \dfrac{1 - \cos x}{x^2} 
            & = \lim_{x \rightarrow 0} \dfrac{1 - \cos x}{x^2} \dfrac{1+\cos x}{1+\cos x} = \\
            & = \lim_{x \rightarrow 0} \dfrac{1 - \cos^2 x}{x^2} \dfrac{1}{1+\cos x} = \\ 
            & = \lim_{x \rightarrow 0} \underbrace{\dfrac{\sin^2 x}{x^2}}_{\left( \frac{\sin x}{x} \right)^2 \rightarrow 1} \underbrace{\dfrac{1}{1+\cos x}}_{\rightarrow \frac{1}{2}} = \frac{1}{2}
        \end{aligned}
    \end{equation}
\end{proof}

{\color{red}
\noindent
REMOVE from here, MOVE to chapter about series
\begin{definition}[Il numero di Nepero, $e$] Il numero di Nepero, $e$ può essere definito come il limite
    \begin{equation}
        e := \lim_{n \rightarrow \infty} \left( 1 + \dfrac{1}{n} \right)^n \ .
    \end{equation}
\end{definition}
Si prova l'esistenza al finito di questo limite, dimostrando che la serie $a_n := \left( 1 + \frac{1}{n} \right)^n $ è:
\begin{itemize}
    \item crescente in maniera monotona, i.e. $a_{n+1} > a_n$, $\forall n$
    \item limitata superiormente, i.e. $\exists M s.t. a_n < M$, $\forall n$
\end{itemize}
Per dimostrare che la serie è crescente, cerchiamo il legame tra due termini successivi.
Per dimostrare che la serie è limitata superiormente, dimostriamo che $a_n < 3$.
}

\begin{proof}[Limite notevole dell'esponenziale - definizione] Questo limite non è nient'altro che una delle definizioni del numero $e$, come mostrato nella Sez.\S\ref{sec:napier}.
\end{proof}
\begin{proof}[Limite notevole dell'esponenziale - (1)]
    \begin{equation}
        \begin{aligned}
            \lim_{x \rightarrow 0} \dfrac{e^x - 1}{x} 
            & = \lim_{x \rightarrow 0} \dfrac{1}{x}\sum_{k=0}^{\infty} \left( \dfrac{x^k}{k!} - 1 \right) = \\
            & = \lim_{x \rightarrow 0} \dfrac{1}{x}\sum_{k=1}^{\infty} \dfrac{x^k}{k!} = \\
            & = \lim_{x \rightarrow 0} \dfrac{1}{x} \left( x + \dfrac{x^2}{2} + \dfrac{x^3}{3!} + \dots  \right) = \\
            & = \lim_{x \rightarrow 0} \left( 1 + \dfrac{x}{2} + \dfrac{x^2}{3!} + \dots  \right) = 1 
        \end{aligned}
    \end{equation}
\end{proof}
\begin{proof}[Limite notevole dell'esponenziale - (2)]
    \begin{equation}
        \begin{aligned}
            \lim_{x \rightarrow 0} \dfrac{e^x}{1+x} 
            & = \lim_{x \rightarrow 0} \dfrac{1}{1+x}\sum_{k=0}^{\infty} \dfrac{x^k}{k!} = \\
            & = \lim_{x \rightarrow 0} \dfrac{1}{1+x}\left( 1 + x + \dfrac{x^2}{2} + \dfrac{x^3}{3!} + \dots \right) = \\
            & = \lim_{x \rightarrow 0} \bigg[ 1 + \underbrace{\dfrac{x^2}{1+x} \left( \dfrac{1}{2} + \dfrac{x}{3!} + \dots \right)}_{\rightarrow 0} \bigg] = 1 \\
        \end{aligned}
    \end{equation}
\end{proof}
\begin{proof}[Limite notevole del logaritmo]
    \begin{equation}
        \begin{aligned}
            \lim_{x \rightarrow 0} \dfrac{e^x}{1+x} 
            & = \lim_{x \rightarrow 0} \dfrac{1}{1+x}\sum_{k=0}^{\infty} \dfrac{x^k}{k!} = \\
            & = \lim_{x \rightarrow 0} \dfrac{1}{1+x}\left( 1 + x + \dfrac{x^2}{2} + \dfrac{x^3}{3!} + \dots \right) = \\
            & = \lim_{x \rightarrow 0} \bigg[ 1 + \underbrace{\dfrac{x^2}{1+x} \left( \dfrac{1}{2} + \dfrac{x}{3!} + \dots \right)}_{\rightarrow 0} \bigg] = 1 \\
        \end{aligned}
    \end{equation}
\end{proof}

% =======================================================================================
\chapter{Derivate}\label{ch:derivatives}

% ---------------------------------------------------------------------------------------
\section{Definizioni}
\begin{definition}[Rapporto incrementale]
\begin{equation}
    \dfrac{f(x+\Delta x) - f(x)}{\Delta x}
\end{equation}
\end{definition}

\begin{definition}[Derivata]
\begin{equation}
  f'(x) = \dfrac{d }{dx} f(x) := \lim_{\Delta x \rightarrow 0} \dfrac{f(x+\Delta x) - f(x)}{\Delta x}
\end{equation}
\end{definition}

\begin{definition}
\end{definition}

\paragraph{Interpretazione geometrica.}

% ---------------------------------------------------------------------------------------
\section{Regole di derivazione}
\subsection{Regole}
\paragraph{Derivata della somma di due funzioni e il prodotto per uno scalare}
\begin{equation}
\begin{aligned}
    (f(x) + g(x))' & = f'(x) + g'(x) \\
    (a f(x))' & = a f'(x) \\
\end{aligned}
\end{equation}
\begin{property}[Operatore lineare] La derivata è un operatore lineare.
\end{property}

\paragraph{Derivata del prodotto di due funzioni}
\begin{equation}
    (f(x) g(x))' = f'(x) g(x) + f(x) g'(x)
\end{equation}
\paragraph{Derivata del rapporto di due funzioni}
\begin{equation}
    \left( \dfrac{f(x)}{g(x)} \right)' = \dfrac{f'(x)g(x) - f(x)g'(x)}{g^2(x)}
\end{equation}
\paragraph{Derivata di una funzione composta}
\begin{equation}
    \dfrac{d}{dx} f(g(x)) = \dfrac{d}{dy} f(y) \bigg|_{y=g(x)} \dfrac{d}{dx} g(x)
\end{equation}
\paragraph{Derivata della funzione inversa}
\begin{equation}
\end{equation}

\subsection{Dimostrazioni}

\paragraph{Derivata della somma di due funzioni}
\paragraph{Derivata del prodotto di due funzioni}
\begin{equation}
\begin{aligned}
\dfrac{d}{dx} \left(f(x) g(x) \right) & =
     \lim_{\Delta x \rightarrow 0} \dfrac{f(x+\Delta x) g(x+\Delta x) - f(x)g(x) }{\Delta x} =  \\
 & = \lim_{\Delta x \rightarrow 0} \dfrac{f(x+\Delta x) g(x+\Delta x) - f(x+\Delta x) g(x) + f(x+\Delta x) g(x) - f(x)g(x) }{\Delta x} =  \\
 & = \lim_{\Delta x \rightarrow 0} \dfrac{f(x+\Delta x) g(x+\Delta x) - f(x+\Delta x) g(x) + f(x+\Delta x) g(x) - f(x)g(x) }{\Delta x} =  \\
    & = \lim_{\Delta x \rightarrow 0} f(x+\Delta x) \dfrac{ g(x+\Delta x) - g(x)}{\Delta x} + \lim_{\Delta x \rightarrow 0} \dfrac{ f(x+\Delta x)  - f(x) }{\Delta x} g(x) =  f'(x)g(x) + f(x)g'(x) \ .
\end{aligned}
\end{equation}
\paragraph{Derivata del rapporto di due funzioni}
\begin{equation}
\begin{aligned}
    \dfrac{d}{dx} \left(\dfrac{f(x)}{ g(x)} \right) & =
     \lim_{\Delta x \rightarrow 0} \dfrac{1}{\Delta x} \left[ \dfrac{f(x+\Delta x)}{ g(x+\Delta x)} - \dfrac{f(x)}{g(x)} \right] =  \\
    & = \lim_{\Delta x \rightarrow 0} \dfrac{1}{\Delta x} \dfrac{f(x+\Delta x) g(x) - f(x)g(x+\Delta x)}{g(x+\Delta x)g(x)}  =  \\
    & = \lim_{\Delta x \rightarrow 0} \dfrac{1}{g(x+\Delta x)g(x)} \dfrac{f(x+\Delta x) g(x) - f(x) g(x) + f(x)g(x)  - f(x)g(x+\Delta x)}{\Delta x}  =  \\
    & = \lim_{\Delta x \rightarrow 0} \dfrac{1}{g(x+\Delta x)g(x)} \dfrac{f(x+\Delta x) - f(x)}{\Delta x} g(x) - \lim_{\Delta x \rightarrow 0} \dfrac{1}{g(x+\Delta x)g(x)} \dfrac{g(x+\Delta x) - g(x)}{\Delta x} f(x) =  \\
    & = \dfrac{f'(x) g(x)}{g^2(x)} - \dfrac{f(x)g'(x)}{g^2(x)} = \dfrac{f'(x)g(x) - f(x) g'(x)}{g^2(x)}
\end{aligned}
\end{equation}
\paragraph{Derivata di una funzione composta}
\begin{equation}
\begin{aligned}
    \dfrac{d}{dx} f(g(x)) & =
     \lim_{\Delta x \rightarrow 0} \dfrac{1}{\Delta x} \left[ f(g(x+\Delta x)) - f(g(x)) \right] =  \\
    & = \lim_{\Delta x \rightarrow 0} \dfrac{f(g(x+\Delta x)) - f(g(x))}{g(x+\Delta x) - g(x)} \dfrac{g(x+\Delta x) - g(x)}{\Delta x} =  \\
    & = \dots \\
    & = f'(g(x)) \, g'(x) \ .
\end{aligned}
\end{equation}

% ---------------------------------------------------------------------------------------
\section{Teoremi}
\begin{theorem}[Teorema di Fermat]\label{thm:fermat} Sia $f: \ (a,b) \rightarrow \mathbb{R}$ una funzione definita sull'intervallo $(a,b)$ e derivabile nel punto $x_0 \in (a,b)$, punto di estremo locale. Allora $f'(x_0) = 0$.
\end{theorem}

\begin{theorem}[Teorema di Rolle]\label{thm:rolle} Sia $f: \ [a,b] \rightarrow \mathbb{R}$ una funzione continua e derivabile in ogni punto dell'intervallo $[a,b]$ che assume valori uguali $f(a) = f(b)$, allora esiste almeno un punto $c \in (a,b)$ in cui la derivata della funzione si annulla, $f'(c) = 0$.
\end{theorem}
\begin{proof}
    Secondo il teorema di Weierstrass (\ref{thm:weierstrass}) sulle funzioni continue, la funzione $f$ ammette punti $c \in [a,b]$ di massimo e un minimo globali. Si possono riconoscere ora due casi:
    \begin{itemize}
        \item se i punti di massimo e minimo globali coincidono entrambi con gli estremi dell'intervallo, si può scrivere
            \begin{equation} m = f(a) = f(b) \le f(x) \le M = f(a) = f(b) \end{equation}
                e quindi la funzione è costante, $f(x) = f(a) = f(b)$, e la sua derivata è nulla in tutti i punti dell'intervallo,$f'(x) = 0, \ \forall x \in (a,b)$;
            \item altrimenti, esiste un punto di massimo o minimo globale $x=c \in (a,b)$ interno all'intervallo; i punti di massimo o minimo globali globali sono anche punti di massimo o minimo locali e quindi, per il teorema di Fermat (\ref{thm:fermat}), $f'(c) = 0$.
    \end{itemize} 
\end{proof}

\begin{theorem}[Teorema di Cauchy]\label{thm:cauchy} Siano $f, g: \ [a,b] \rightarrow \mathbb{R}$ due funzioni continue in $[a,b]$ e derivabili su $(a,b)$, allora esiste un punto $c \in (a,b)$ tale che
    \begin{equation}
        \left[ f(b) - f(a)  \right]g'(c) = \left[ g(b) - g(a)  \right]f'(c) \ .
    \end{equation}
\end{theorem}
\begin{proof}
  La dimostrazione del teorema di Cauchy può essere svolta con un'opportuna scelta della funzione alla quale applicare il teorema di Rolle (\ref{thm:rolle}). Ad esempio, la funzione
    \begin{equation}
       h(x) = [f(b) - f(a)] [ g(x) - g(a)] - [g(b)-g(a)] [f(x) - f(a)] \ ,
    \end{equation}
    soddisfa le ipotesi del teoremda di Rolle, poichè
    \begin{itemize}
        \item $h(x)$ è continua su $[a,b]$ e derivabile su $(a,b)$
        \item $h(a) = h(b)$, dal calcolo diretto
            \begin{equation}
                \begin{aligned}
                    h(a) & = [f(b) - f(a)] [ g(a) - g(a)] - [g(b)-g(a)] [f(a) - f(a)] = 0 \\ 
                    h(b) & = [f(b) - f(a)] [ g(b) - g(a)] - [g(b)-g(a)] [f(b) - f(a)] = 0  \ .
                \end{aligned}
            \end{equation}
    \end{itemize}
    Applicando il teorema di Rolle alla funzione $h(x)$, possiamo concludere che esiste un punto $c \in (a,b)$ tale che $h'(c) = 0$ e quindi
    \begin{equation}
        0 = h'(c) = [f(b) - f(a)] g'(x) - [g(b)-g(a)] f'(x) \ .
    \end{equation}
\end{proof}

\begin{theorem}[Teorema di Lagrange]\label{thm:lagrange} Sia $f: \ [a,b] \rightarrow \mathbb{R}$ una funzione continua in $[a,b]$ e derivabile in $(a,b)$, allora esiste un punto $c \in (a,b)$ tale che
    \begin{equation}
        f(b) - f(a) = f'(c) (b-a) \ .
    \end{equation}
\end{theorem}
\begin{proof}
    La dimostrazione del teorema di Lagrange segue direttamente dalla dimostrazione del teorema di Cauchy (\ref{thm:cauchy}), usando le funzioni $f(x)$ e $g(x) = x$, la cui derivata è $g'(x) = 1$.
\end{proof}

\subsection{Teorema di de l'Hopital}
\begin{theorem}[Teorema di de l'Hopital]\label{thm:hopital}
\end{theorem}

% ------------------------------------------------------------------------------
\section{Derivate fondamentali}
\begin{center}
    \begin{tabular}{lll}
        Potenza      & $f(x) = x^a$       & $f'(x) = a x^{a-1}$    \\
        Esponenziale & $f(x) = e^x$       & $f'(x) = e^x$          \\
        Logaritmo    & $f(x) = \ln x$     & $f'(x) = \frac{1}{x}$  \\
        Seno         & $f(x) = \sin x$    & $f'(x) = \cos x$       \\
        Coseno       & $f(x) = \cos x$    & $f'(x) =-\sin x$       \\
    \end{tabular}
\end{center}
\subsection{Dimostrazioni}
\begin{proof}[Derivata della potenza]
\begin{equation}
    \begin{aligned}
    (x^n)'
        & = \lim_{\varepsilon \rightarrow 0 } \dfrac{(x+\varepsilon)^n - x^n}{\varepsilon} = \\
        & = \lim_{\varepsilon \rightarrow 0 } \dfrac{ \left( 1 + \frac{\varepsilon}{x} \right)^n - 1 }{\varepsilon} x^n = \\
        & = \underbrace{\lim_{\varepsilon \rightarrow 0 } \dfrac{ \left( 1 + \frac{\varepsilon}{x} \right)^n - 1 }{\frac{\varepsilon}{x}}}_{=n} x^{n-1} = \\
        & = n x^{n-1}
    \end{aligned}
\end{equation}
\end{proof}

\begin{proof}[Derivata della funzione esponenziale]
\begin{equation}
    \begin{aligned}
        (e^x)' 
        & = \lim_{\varepsilon \rightarrow 0 } \dfrac{e^{x+\varepsilon} - e^x}{\varepsilon} = \\
        & = \underbrace{\lim_{\varepsilon \rightarrow 0 } \dfrac{(e^{\varepsilon} - 1)}{\varepsilon}}_{= 1} e^{x} = \\
        & = e^x
    \end{aligned}
\end{equation}
\end{proof}
\begin{proof}[Derivata della funzione logaritmo] {\color{red} Il dominio della funzione logaritmo è $\mathbb{R}^+$, ossia l'insieme dei numeri reali positivi. Essendo l'argomento del logaritmo diverso da zero, si può dividere per esso senza il timore di incorrere in espressioni non definite}
\begin{equation}
    \begin{aligned}
        (\ln x)' 
        & = \lim_{\varepsilon \rightarrow 0 } \dfrac{\ln(x+\varepsilon) - \ln x}{\varepsilon} = \\
        & = \lim_{\varepsilon \rightarrow 0 } \dfrac{\ln \left( x\left( 1 + \frac{\varepsilon}{x} \right) \right) - \ln x}{\varepsilon} = \\
        & = \lim_{\varepsilon \rightarrow 0 } \dfrac{\ln  x + \ln \left( 1 + \frac{\varepsilon}{x}  \right) - \ln x}{\varepsilon} = \\
        & = \lim_{\varepsilon \rightarrow 0 } \dfrac{ \ln \left( 1 + \frac{\varepsilon}{x}  \right) }{\varepsilon} = \\
        & = \underbrace{\lim_{ \small\begin{matrix} \varepsilon \rightarrow 0 \\  \varepsilon / x \rightarrow 0  \end{matrix}} \dfrac{ \ln \left( 1 + \frac{\varepsilon}{x}  \right) }{\frac{\varepsilon}{x}}}_{=1} \dfrac{1}{x} = \\
        & = \dfrac{1}{x}
    \end{aligned}
\end{equation}
\end{proof}
\begin{proof}[Derivata della funzione seno]
\begin{equation}
    \begin{aligned}
        (\sin x)' 
        & = \lim_{\varepsilon \rightarrow 0 } \dfrac{\sin(x+\varepsilon) - \sin x}{\varepsilon} = \\
        & = \lim_{\varepsilon \rightarrow 0 } \dfrac{\sin x \cos\varepsilon + \sin \varepsilon \cos x - \sin x}{\varepsilon} = \\
        & = \underbrace{\lim_{\varepsilon \rightarrow 0 } \left( \dfrac{ \cos\varepsilon - 1}{\varepsilon} \right) }_{\lim_{\varepsilon \rightarrow 0} \left(-\frac{1}{2} \varepsilon \right) = 0 } \sin x +  \underbrace{\lim_{\varepsilon \rightarrow 0 } \dfrac{\sin \varepsilon}{\varepsilon} }_{= 1} \cos x  = \\
        & = \cos x 
    \end{aligned}
\end{equation}
\end{proof}
\begin{proof}[Derivata della funzione coseno]
\begin{equation}
    \begin{aligned}
        (\cos x)' 
        & = \lim_{\varepsilon \rightarrow 0 } \dfrac{\cos(x+\varepsilon) - \cos x}{\varepsilon} = \\
        & = \lim_{\varepsilon \rightarrow 0 } \dfrac{\cos x \cos\varepsilon - \sin \varepsilon \sin x - \cos x}{\varepsilon} = \\
        & = \underbrace{\lim_{\varepsilon \rightarrow 0 } \left( \dfrac{ \cos\varepsilon - 1}{\varepsilon} \right) }_{\lim_{\varepsilon \rightarrow 0} \left(-\frac{1}{2} \varepsilon \right) = 0 } \cos x -  \underbrace{\lim_{\varepsilon \rightarrow 0 } \dfrac{\sin \varepsilon}{\varepsilon} }_{= 1} \sin x  = \\
        & = - \sin x 
    \end{aligned}
\end{equation}
\end{proof}

\section{Derivate di ordine superiore}

\section{Espansioni in serie di Taylor e MacLaurin}\label{ch:taylor}
\begin{definition}[Serie di Taylor] La serie di Taylor di una funzione $f(x)$ centrata in $x=x_0$ è la serie polinomiale
\begin{equation}
   T[f(x_0)](x) := \sum_{n=0}^{\infty} \dfrac{f^{(n)}(x_0)}{n!} (x-x_0)^n \ .
\end{equation}
\end{definition}
%
\begin{theorem}
La serie di Taylor troncata alla $n$-esima potenza,
\begin{equation}
  T^n[f(x_0)](x) = \sum_{k=0}^{n} \dfrac{f^{(k)}(x_0)}{i!} (x-x_0)^k \ ,
\end{equation}
è un'approssimazione dell'$n$-esimo ordine della funzione $f(x)$, i.e.
\begin{equation}
  f(x) - T^n[f(x_0)](x) \sim o(|x-x_0|^{n})
\end{equation}
\end{theorem}

\begin{definition}[Serie di MacLaurin] La serie di MacLaurin di una funzione $f(x)$ è definita come la sua serie di Taylor centrata in $x=0$.
\end{definition}


\section{Applicazioni}
\subsection{Punti in cui $f'(x) = 0$: punti di estremo locale e flessi orizzontali}
Per una funzione derivabile, i punti in cui si annulla la derivata prima di una funzione $f(x)$ possono essere:
\begin{itemize}
    \item punti di massimo locale
    \item punti di minimo locale
    \item punti di flesso orizzontale
\end{itemize}
\begin{definition}[Punto di massimo locale]
\end{definition}
\begin{theorem}[Condizioni per un punto di massimo locale] Il punto $x_0$ è un punto di massimo locale per una funzione $f(x)$ derivabile se
    \begin{itemize}
        \item $f'(x_0) = 0$
        \item la prima derivata di ordine superiore valutata in $x_0$ diversa da zero, è una derivata di \textbf{ordine pari} ed è \textbf{negativa}, $f^{(n)}(x_0) < 0$
    \end{itemize}
\end{theorem}
\begin{definition}[Punto di minimo locale]
\end{definition}
\begin{theorem}[Condizioni per un punto di minimo locale] Il punto $x_0$ è un punto di mimimo locale per una funzione $f(x)$ derivabile se
    \begin{itemize}
        \item $f'(x_0) = 0$
        \item la prima derivata di ordine superiore valutata in $x_0$ diversa da zero, è una derivata di \textbf{ordine pari}, ed è \textbf{positiva}, $f^{(n)}(x_0) > 0$
    \end{itemize}
\end{theorem}
\begin{definition}[Punto di flesso orizzontale]
\end{definition}
\begin{theorem}[Condizioni per un punto di flesso orizzontale] Il punto $x_0$ è un punto di flesso orizzontale per una funzione $f(x)$ derivabile se
    \begin{itemize}
        \item $f'(x_0) = 0$
        \item la prima derivata di ordine superiore valutata in $x_0$ diversa da zero, è una derivata di \textbf{ordine dispari}
    \end{itemize}
\end{theorem}

\subsection{Punti in cui $f''(x) = 0$: punti di flesso}

\subsection{Studio funzione}

% =======================================================================================
\chapter{Integrali}\label{ch:integrals}

\section{Definizioni}
\begin{definition}[Somma di Riemann] Data una funzione continua $f:[a,b] \rightarrow \mathbb{R}$, e una partizione $\mathcal{P} = \left\{x_0, x_1, \dots, x_n | a = x_0 < x_1 < \dots x_n = b \right\}$ dell'intervallo $[a,b]$, la somma di Riemann viene definita come
    \begin{equation}
        \sigma_n = \sum_{i=1}^{n} f(\xi_i) \ (x_{i} - x_{i-1})
    \end{equation}
con $\xi_i \in [x_{i-1}, x_i]$.
\end{definition}

\begin{definition}[Integrale di Riemann]\label{def:riemann-integral} Definendo $\Delta x := \max_i(x_i - x_{i-1}) $, l'integrale di Riemann viene definito come il limite della somma di Riemann per $\Delta x  \rightarrow 0$ (e di conseguenza il numero di intervalli della partizione $n \rightarrow \infty$), e viene indicato come
    \begin{equation}
        \int_{x=a}^b f(x) dx = \lim_{\Delta x \rightarrow 0} \sigma_n
    \end{equation}
\end{definition}

\begin{definition}[Integrale definito] L'integrale della definizione (\ref{def:riemann-integral}) svolto tra due valori di $x$ viene definito integrale definito. 
\end{definition}

\paragraph{Interpretazione geometrica}

\begin{definition}[Integrale indefinito]
\end{definition}

\section{Proprietà}
\begin{equation}
    \int_{x=a}^{b} \left[ A f(x) + B g(x) \right] dx = A \int_{x=a}^{b} f(x) dx + B \int_{x=a}^{b} g(x) dx
\end{equation}
\begin{equation}
    \int_{x=a}^{b} f(x) dx = \int_{x=a}^{c} f(x) dx + \int_{x=c}^{b} f(x) dx
\end{equation}

\section{Teoremi}
\begin{definition}[Media]
    \begin{equation}
        M(f, [a,b]) = \dfrac{1}{b-a} \int_{x=a}^{b} f(x) dx
    \end{equation}
\end{definition}

\begin{theorem}[Teorema della media]
    Sia $f: \ [a,b] \rightarrow \mathbb{R}$ una funzione continua su $[a,b]$, allora esiste un punto $c \in [a,b]$ tale che
    \begin{equation}
        \int_{x=a}^{b} f(x) dx = f(c) (b-a) \ .
    \end{equation}
\end{theorem}
\begin{proof}
    La dimostrazione è immediata, applicando il teorema di Lagrange (\ref{thm:lagrange}) alla primitiva $F(x)$ della funzione $f(x)$, $F(x) = \int_{t=x_0}^{x} f(t) dt$ 
\begin{equation}
    \int_{t=a}^{b} f(x) dx = F(b) - F(a) = F'(c) (b-a) = f(c) (b-a) \ .
\end{equation}
\end{proof}


\begin{theorem}[Teorema fondamentale del calcolo infinitesimale]
    \begin{equation}
        \dfrac{d}{dx} \int_{t=a}^{x} f(t) dt = f(x)
    \end{equation}
\end{theorem}
\begin{equation}
    \begin{aligned}
        \dfrac{d}{dx} \int_{t=a}^{x} f(t) dt & = 
        \lim_{\Delta x \rightarrow 0} \dfrac{1}{\Delta x} \left[ \int_{t=a}^{x+\Delta x} f(t) dt - \int_{t=a}^{x} f(t) dt\right] = \\
        & = \lim_{\Delta x \rightarrow 0} \dfrac{1}{\Delta x} \int_{t=x}^{x+\Delta x} f(t) dt = \\
        & = \lim_{\Delta x \rightarrow 0} \dfrac{1}{\Delta x} \Delta x \, f(\xi) = \qquad \qquad \qquad \text{(con $\xi \in [x, x+\Delta x]$)} \\
        & = f(x)  \  .
    \end{aligned}
\end{equation}

\section{Integrali fondamentali}

\section{Regole di integrazione}
\subsection{Integrazione per parti}
\begin{itemize}
 \item Definendo $F(x)$, $G(x)$ le primitive delle funzioni $f(x)$, e $g(x)$
 \item Integrando in $x$ dalla regola di \textbf{derivazione del prodotto} $(F(x)G(x))' = F'(x)G(x) + F(x)G'(x)$, riscritta isolando il termine $F'(x)G(x) = (F(x)G(x))' - F(x)G'(x)$
\end{itemize}
si ottiene
\begin{equation}
\begin{aligned}
    \int f(x) G(x) dx & = \int (F(x) G(x))' dx - \int F(x) G'(x) dx = \\
    &= F(x)G(x) - \int F(x) G'(x) dx 
\end{aligned}
\end{equation}

\begin{example}
\end{example}

\subsection{Integrazione con sostituzione}
\begin{itemize}
    \item Definendo la funzione composta $\overline{F}(x) = F(y(x))$ e le derivate
        \begin{equation}
            \overline{f}(x) = \dfrac{d}{dx} \overline{F}(x) \qquad , \qquad f(y) = \dfrac{d}{dy}F(y)
        \end{equation}
    \item Partendo dalla regola di \textbf{derivazione della funzione composta}, $\overline{F}(x) = F(y(x))$
        \begin{equation}
            \overline{f}(x) = \dfrac{d}{dx} \overline{F}(x) = \dfrac{d}{dx} F(y(x)) = \dfrac{d F}{dy}(y(x)) \dfrac{d y}{d x}(x) = f(y(x)) y'(x)
        \end{equation}
\end{itemize}
Usando il teorema fondamentale del calcolo infinitesimale
\begin{equation}
\begin{aligned}
    F(y) & = \int f(y) dy \\
    \overline{F}(x) & = \int \overline{f}(x) dx = \int f(y(x)) \ y'(x) dx
\end{aligned}
\end{equation}
Se si introduce la dipendenza $y(x)$ nella prima equazione, si ottiene l'uguaglianza tra le ultime due espressioni, $F(y(x)) = \overline{F}(x)$, e quindi
\begin{equation}
  \int f(y) dy = \int f(y(x)) \ y'(x) dx \ .
\end{equation}

\begin{example}
\end{example}
